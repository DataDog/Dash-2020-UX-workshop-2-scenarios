The datadog agent can monitor and send metrics from our backend, but it's not aimed at understanding the user experience.

With the increasing scale of our application, testing after each change to catch regressions will become longer and more tedious.
Imagine browsing all the critical paths of an application to make sure they are still behaving correctly.
At some point, it won't realistically be done manually.
Let's see how to automate these tests with end-to-end testing.

To do so, Datadog provides two tools: Synthetics tests.
They replays critical user interactions to make sure the application is behaving correctly.

In this workshop, we will create some test to monitor some critical parts of our application and make sure they are always visible and available.

## Marketing Memo

So the marketing team sent us a report showing that the discounts insert is driving 83% of the site's revenue.

![](assets/marketing-memo.png)

It's definitely something we don't want to miss, let's record a test to make sure it doesn't break!
The test we are going to create will allow us to proactively monitor that the discounts codes are always appearing on the application.

The Synthetics tool is under the UX Monitoring menu.
![](assets/synthetics.png)

The first time, we might be greeted by a welcome screen to explain what UX Monitoring, RUM and Synthetics are. Let's browse past that for now.
![](assets/synthetics-greetings.png)

It'll ask us to create a first synthetics test.
If there isn't the greeting followed by the creation pop-up, there is a button on the top right corner to create a test.
![](assets/synthetics-start.png)

## Test details

The first page we land on while creating the test is the _test details_ page.

### Url
We can fill in the url the test will start on.
This is the url of our storedog application.

### Name
We then create a name for our test.
Here I put _"Disocunt insert is live and ok"_

### Tags
We can add tags to group tests together, to help browse in all our tests, and so on.
I didn't put any tags as we will create only one test, but feel free to add some later on.

### Devices
We can choose on which device our test will run, or on all devices.
With our development environment, we often test our application on desktop, and it often takes an extra step to test on mobile as well.
So this is especially handy to make sure our application is behave correctly on mobile as well.

### Location
We can run our synthetics test on a large number of locations, to simulate the location of our final users.
It's possible to select as many location as we want, but in the case of this workshop, one is enough.

![](assets/synthetics-details-1.png)

### Frequency
We can choose at which frequency our test will run.
The default of a test run every hour is good enough.
If we were to test something really critical, we could push that to 5mn, or for lesser browsed pages, we could test only a few times a day, or a week.
Let's leave that to 1h for now.

### Alert
This might be one of the most important part of the test!
We can specify how relaxed the alerting is, to allow for a few failures before warning us.
This is especially useful to filter transient errors that resolve themselves in a few minutes or so.
Let's leave that for now, and specify our mail to receive an alert in case the test would fail.

![](assets/synthetics-details-2.png)

Once everything is filled, we can click on the _Save & Edit Recording_ button to start recording the actions our step will replay.

## Installing the extension

While recording a synthetics test, we catch all interactions with the page in the recorded tab. To do so correctly, we need to install an extension in the browser.

[Datadog Synthetics Chrome Extension](https://chrome.google.com/webstore/detail/datadog-test-recorder/kkbncfpddhdmkfmalecgnphegacgejoa)

This extension is only available for Chrome for now.
> Firefox users: you can still continue your workshop with firefox, and switch to Chrome only for the recording part. To do so, simply copy and paste the url in Chrome, install the extension, and you should be good to go.
Though, let us know if you are interested in having the recorder ported, to help us prioritize it.

Once the extension is installed, we can record our first test.

## Discount insert is present

The first test we are going to record is fairly simple: we will make sure the element containing the discount code is present in the page.

First let's create an assertion by clicking on the _Assertion_ button.
It might come off obvious but it's always good to remind: tests should always contain at least one assertion, and finish on an assertion.
![](assets/synthetics-elm-present-1.png)

We are going to assert the discount insert is visible by making sure its element is present on the page.
Let's click on _Test that an element is present_.
![](assets/synthetics-elm-present-2.png)

Then, we are asked to select which element should be present on the page.
Let's click on the element containing the discount code.
![](assets/synthetics-elm-present-3.png)

And done, we just created our first assertion that the discount code is visible.
![](assets/synthetics-elm-present-4.png)

Let's see that this test is working.
We can save the test by clicking on the button "Save & launch the test" at the very bottom of the page.
![](assets/synthetics-elm-present-5.png)

And after a couple minutes, we should see our first results coming in.
The test is live and seems to be working!
![](assets/synthetics-elm-present-6.png)

You might have noticed that the content of the element is always changing, and yet we still manage to find it in the page.
Our localization algorithms uses various strategies to locate an element. Some of them are based on the content of the element, but not all.
So if the text of the element is changing, the other localization strategies can take lead. And if the element is moving in the DOM, or if its `id` or `class` are changing, the content-based strategies can take lead to always find the right element.
And if the element is detected to be modified, all the strategies are updated automatically so that all the strategies are working for the next test.

## Discount insert is displayed as expected

Let's dive in a bit deeper and record a test to make sure the discount code actually displayed as expected.

Let's create a new step in our existing test.
Click on the cog, in the top right corner, and then on _Edit recording_
![](assets/synthetics-elm-expected-1.png)

We are now back in the steps list, and ready to record our new step.
Let's click again on the assertion button, but now, let's choose _Test an element's content_.
![](assets/synthetics-elm-expected-2.png)

We choose again the same element containing the discount code, and we would like to test that its content is what we expect, even though it's changing every time.
We can use the regex assertion.
![](assets/synthetics-elm-expected-3.png)

We want the discount code to be between 3 to 8 letters.
`^Enter coupon code '[A-Z]{3,8}' at checkout`{{copy}}
![](assets/synthetics-elm-expected-4.png)
Let's save and check that our test is still green.
